{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1SkVPyEma1_gJPOLqujVWt72FQtZau-ql","authorship_tag":"ABX9TyMY/mwl3oGdno6N6FSq1g4F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"CzPVvsObas9G","executionInfo":{"status":"ok","timestamp":1692540535258,"user_tz":-540,"elapsed":525,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"8e9cdf7e-3737-4ca6-9448-a5ff5ca45d67"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           region  year manufacturer  condition    cylinders fuel  odometer  \\\n","id                                                                            \n","0       nashville  1949          bmw  excellent  6 cylinders  gas    115148   \n","1   state college  2013       toyota       fair  8 cylinders  gas    172038   \n","2         wichita  1998         ford       good  6 cylinders  gas    152492   \n","3          albany  2014         ford  excellent  4 cylinders  gas    104118   \n","4         redding  2005         ford  excellent  6 cylinders  gas    144554   \n","\n","   title_status transmission drive       size         type paint_color state  \\\n","id                                                                             \n","0         clean       manual   rwd   mid-size  convertible      orange   NaN   \n","1         clean    automatic   rwd  full-size        sedan      silver    pa   \n","2         clean    automatic   fwd  full-size          SUV      silver    ks   \n","3         clean       manual   fwd   mid-size          SUV        blue    ny   \n","4         clean       manual   fwd   mid-size        sedan         red    ca   \n","\n","    price  \n","id         \n","0   27587  \n","1    4724  \n","2   10931  \n","3   16553  \n","4    5158  "],"text/html":["\n","  <div id=\"df-46e15d29-deb1-412a-9f35-ff6cfad5e09a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>size</th>\n","      <th>type</th>\n","      <th>paint_color</th>\n","      <th>state</th>\n","      <th>price</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nashville</td>\n","      <td>1949</td>\n","      <td>bmw</td>\n","      <td>excellent</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>115148</td>\n","      <td>clean</td>\n","      <td>manual</td>\n","      <td>rwd</td>\n","      <td>mid-size</td>\n","      <td>convertible</td>\n","      <td>orange</td>\n","      <td>NaN</td>\n","      <td>27587</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>state college</td>\n","      <td>2013</td>\n","      <td>toyota</td>\n","      <td>fair</td>\n","      <td>8 cylinders</td>\n","      <td>gas</td>\n","      <td>172038</td>\n","      <td>clean</td>\n","      <td>automatic</td>\n","      <td>rwd</td>\n","      <td>full-size</td>\n","      <td>sedan</td>\n","      <td>silver</td>\n","      <td>pa</td>\n","      <td>4724</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wichita</td>\n","      <td>1998</td>\n","      <td>ford</td>\n","      <td>good</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>152492</td>\n","      <td>clean</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>full-size</td>\n","      <td>SUV</td>\n","      <td>silver</td>\n","      <td>ks</td>\n","      <td>10931</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>albany</td>\n","      <td>2014</td>\n","      <td>ford</td>\n","      <td>excellent</td>\n","      <td>4 cylinders</td>\n","      <td>gas</td>\n","      <td>104118</td>\n","      <td>clean</td>\n","      <td>manual</td>\n","      <td>fwd</td>\n","      <td>mid-size</td>\n","      <td>SUV</td>\n","      <td>blue</td>\n","      <td>ny</td>\n","      <td>16553</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>redding</td>\n","      <td>2005</td>\n","      <td>ford</td>\n","      <td>excellent</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>144554</td>\n","      <td>clean</td>\n","      <td>manual</td>\n","      <td>fwd</td>\n","      <td>mid-size</td>\n","      <td>sedan</td>\n","      <td>red</td>\n","      <td>ca</td>\n","      <td>5158</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46e15d29-deb1-412a-9f35-ff6cfad5e09a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-46e15d29-deb1-412a-9f35-ff6cfad5e09a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-46e15d29-deb1-412a-9f35-ff6cfad5e09a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1b48e78a-c2ec-45bf-93bb-d7c7d10ae6ea\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b48e78a-c2ec-45bf-93bb-d7c7d10ae6ea')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1b48e78a-c2ec-45bf-93bb-d7c7d10ae6ea button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":39}],"source":["\n","import pandas as pd\n","\n","df_train = pd.read_csv('/content/drive/MyDrive/00_signate/中古自動車/train.csv')\n","df_train.set_index('id', inplace=True)\n","df_train.head()"]},{"cell_type":"code","source":["!git config --global user.email \"nomukapi@outlook.jp\"\n","!git config --global user.name \"nomukapi\"\n"],"metadata":{"id":"u464BnZ-gKdx","executionInfo":{"status":"ok","timestamp":1693149057064,"user_tz":-540,"elapsed":540,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/00_signate\n","!git clone https://github.com/nomusanma/test2.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voPldETNg54v","executionInfo":{"status":"ok","timestamp":1693149282500,"user_tz":-540,"elapsed":1445,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"b16d3013-de8c-430c-fd07-8761608ae3b3"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/00_signate\n","Cloning into 'test2'...\n","warning: You appear to have cloned an empty repository.\n"]}]},{"cell_type":"code","source":["!git init\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXeVDJlyjAbJ","executionInfo":{"status":"ok","timestamp":1693149290948,"user_tz":-540,"elapsed":273,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"b564010c-00a6-479b-c8eb-3b0ae35f52ec"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Reinitialized existing Git repository in /content/drive/MyDrive/00_signate/.git/\n"]}]},{"cell_type":"code","source":["!cd LightGBM\n","!git reset --hard\n","!cd ..\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dqr0RZ-vjAUj","executionInfo":{"status":"ok","timestamp":1693149551423,"user_tz":-540,"elapsed":667,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"fede6f39-a815-420e-9080-9713d9d1ef83"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["HEAD is now at db23d7c コミットメッセージ\n"]}]},{"cell_type":"code","source":["# test2/ ディレクトリ内の.gitディレクトリを削除\n","!rm -rf test2/.git\n","\n","# test2/ ディレクトリを追加\n","!git add test2/\n","!git commit -m \"test2ディレクトリの追加\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6n0mLZWohxUO","executionInfo":{"status":"ok","timestamp":1693149617516,"user_tz":-540,"elapsed":779,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"d8fbf8b0-bafe-43ff-82ce-fc7e6550dbe7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch master\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","  (commit or discard the untracked or modified content in submodules)\n","\t\u001b[31mmodified:   LightGBM\u001b[m (untracked content)\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df_test = pd.read_csv('/content/drive/MyDrive/00_signate/中古自動車/test.csv')\n","df_test.set_index('id', inplace=True)\n","df_test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"VFmQHeFcN1WN","executionInfo":{"status":"ok","timestamp":1692540535575,"user_tz":-540,"elapsed":18,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"d231a488-9c1e-4db9-b502-ddbeb38fb690"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 region  year manufacturer  condition    cylinders    fuel  \\\n","id                                                                           \n","27532     western slope  2015    chevrolet  excellent  4 cylinders     gas   \n","27533          roseburg  2013       nissan   like new  4 cylinders     gas   \n","27534    akron / canton  2011   volkswagen       good  4 cylinders     gas   \n","27535            denver  2016         jeep  excellent  6 cylinders  diesel   \n","27536  hickory / lenoir  1999        honda  excellent  8 cylinders     gas   \n","\n","       odometer title_status transmission drive       size   type paint_color  \\\n","id                                                                              \n","27532     92553        clean    automatic   fwd  full-size    SUV         red   \n","27533    134385      salvage    automatic   fwd   mid-size  sedan       black   \n","27534    102489        clean    automatic   fwd  full-size  sedan       black   \n","27535     64310        clean    automatic   4wd   mid-size    SUV         red   \n","27536    180839      rebuilt    automatic   4wd   mid-size    SUV      silver   \n","\n","      state  \n","id           \n","27532   NaN  \n","27533    or  \n","27534    oh  \n","27535    co  \n","27536    nc  "],"text/html":["\n","  <div id=\"df-f18bbf0e-169a-480c-87ad-f8c54e01c411\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>size</th>\n","      <th>type</th>\n","      <th>paint_color</th>\n","      <th>state</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27532</th>\n","      <td>western slope</td>\n","      <td>2015</td>\n","      <td>chevrolet</td>\n","      <td>excellent</td>\n","      <td>4 cylinders</td>\n","      <td>gas</td>\n","      <td>92553</td>\n","      <td>clean</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>full-size</td>\n","      <td>SUV</td>\n","      <td>red</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>roseburg</td>\n","      <td>2013</td>\n","      <td>nissan</td>\n","      <td>like new</td>\n","      <td>4 cylinders</td>\n","      <td>gas</td>\n","      <td>134385</td>\n","      <td>salvage</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>mid-size</td>\n","      <td>sedan</td>\n","      <td>black</td>\n","      <td>or</td>\n","    </tr>\n","    <tr>\n","      <th>27534</th>\n","      <td>akron / canton</td>\n","      <td>2011</td>\n","      <td>volkswagen</td>\n","      <td>good</td>\n","      <td>4 cylinders</td>\n","      <td>gas</td>\n","      <td>102489</td>\n","      <td>clean</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>full-size</td>\n","      <td>sedan</td>\n","      <td>black</td>\n","      <td>oh</td>\n","    </tr>\n","    <tr>\n","      <th>27535</th>\n","      <td>denver</td>\n","      <td>2016</td>\n","      <td>jeep</td>\n","      <td>excellent</td>\n","      <td>6 cylinders</td>\n","      <td>diesel</td>\n","      <td>64310</td>\n","      <td>clean</td>\n","      <td>automatic</td>\n","      <td>4wd</td>\n","      <td>mid-size</td>\n","      <td>SUV</td>\n","      <td>red</td>\n","      <td>co</td>\n","    </tr>\n","    <tr>\n","      <th>27536</th>\n","      <td>hickory / lenoir</td>\n","      <td>1999</td>\n","      <td>honda</td>\n","      <td>excellent</td>\n","      <td>8 cylinders</td>\n","      <td>gas</td>\n","      <td>180839</td>\n","      <td>rebuilt</td>\n","      <td>automatic</td>\n","      <td>4wd</td>\n","      <td>mid-size</td>\n","      <td>SUV</td>\n","      <td>silver</td>\n","      <td>nc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f18bbf0e-169a-480c-87ad-f8c54e01c411')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f18bbf0e-169a-480c-87ad-f8c54e01c411 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f18bbf0e-169a-480c-87ad-f8c54e01c411');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8513209a-9d6b-4771-87fc-82e907a49bda\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8513209a-9d6b-4771-87fc-82e907a49bda')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8513209a-9d6b-4771-87fc-82e907a49bda button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":[],"metadata":{"id":"FQahuPModOO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drop rows with missing values\n","# df = df.dropna()\n","import numpy as np\n","\n","def process(df):\n","    df[\"cylinders\"] = df[\"cylinders\"].fillna(\"none\")\n","    df[\"fuel\"] = df[\"fuel\"].fillna(\"gas\")\n","    df[\"title_status\"] = df[\"title_status\"].fillna(\"none\")\n","    df[\"type\"] = df[\"type\"].fillna(\"none\")\n","    df[\"state\"] = df[\"state\"].fillna(\"none\")\n","    df[\"paint_color\"] = df[\"paint_color\"].fillna(\"none\")\n","    # Correct 'year' values\n","    df['year'] = df['year'].apply(lambda x: int(str(x).replace('29', '19')) if str(x)[:2]=='29' else int(str(x).replace('30', '20')))\n","    df[\"year_sabun\"] =2023-df[\"year\"]\n","    df[\"car\"]=df[\"manufacturer\"]+\"_\"+df[\"type\"]+\"_\"+df[\"drive\"]\n","\n","    # df.loc[df['odometer'] <= 0, 'odometer'] = 0\n","\n","\n","\n","    return df\n","\n","df_train=process(df_train)\n","df_train[\"price_log\"]=np.log1p(df_train[\"price\"])\n","df_test=process(df_test)\n","\n","# Separate features and target variable\n","X = df_train.drop(columns=['price',\"price_log\"])\n","y = df_train[\"price_log\"]\n","\n","X_new_test=df_test.copy()"],"metadata":{"id":"EWVHycMVcaq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# カテゴリカル変数のリスト\n","categorical_features_full =[\"car\",'region', 'manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color', 'state']\n","categorical_features =[\"car\",'region', 'manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color', 'state']\n","# categorical_features =[\"car\", 'manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type']\n","add_list=[]\n","# すべてのカテゴリカル変数のペアの組み合わせを生成\n","for i, feature1 in enumerate(categorical_features):\n","    for j, feature2 in enumerate(categorical_features):\n","        if i < j:  # 同じ特徴の組み合わせを避ける\n","            new_feature_name = feature1 + \"_\" + feature2\n","            X[new_feature_name] = X[feature1].astype(str) + \"_\" + X[feature2].astype(str)\n","            X_new_test[new_feature_name] = X_new_test[feature1].astype(str) + \"_\" + X_new_test[feature2].astype(str)\n","            add_list.append(new_feature_name)\n","\n","categorical_features=categorical_features_full+add_list\n","\n","# 結果の確認\n","X.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"ksIgxyEzQrwS","executionInfo":{"status":"ok","timestamp":1692540536920,"user_tz":-540,"elapsed":1357,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"d6c123fa-9755-4223-a97c-8b4fac742596"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           region  year manufacturer  condition    cylinders fuel  odometer  \\\n","id                                                                            \n","0       nashville  1949          bmw  excellent  6 cylinders  gas    115148   \n","1   state college  2013       toyota       fair  8 cylinders  gas    172038   \n","2         wichita  1998         ford       good  6 cylinders  gas    152492   \n","3          albany  2014         ford  excellent  4 cylinders  gas    104118   \n","4         redding  2005         ford  excellent  6 cylinders  gas    144554   \n","\n","   title_status transmission drive  ...     drive_size       drive_type  \\\n","id                                  ...                                   \n","0         clean       manual   rwd  ...   rwd_mid-size  rwd_convertible   \n","1         clean    automatic   rwd  ...  rwd_full-size        rwd_sedan   \n","2         clean    automatic   fwd  ...  fwd_full-size          fwd_SUV   \n","3         clean       manual   fwd  ...   fwd_mid-size          fwd_SUV   \n","4         clean       manual   fwd  ...   fwd_mid-size        fwd_sedan   \n","\n","   drive_paint_color drive_state             size_type  size_paint_color  \\\n","id                                                                         \n","0         rwd_orange    rwd_none  mid-size_convertible   mid-size_orange   \n","1         rwd_silver      rwd_pa       full-size_sedan  full-size_silver   \n","2         fwd_silver      fwd_ks         full-size_SUV  full-size_silver   \n","3           fwd_blue      fwd_ny          mid-size_SUV     mid-size_blue   \n","4            fwd_red      fwd_ca        mid-size_sedan      mid-size_red   \n","\n","       size_state    type_paint_color        type_state paint_color_state  \n","id                                                                         \n","0   mid-size_none  convertible_orange  convertible_none       orange_none  \n","1    full-size_pa        sedan_silver          sedan_pa         silver_pa  \n","2    full-size_ks          SUV_silver            SUV_ks         silver_ks  \n","3     mid-size_ny            SUV_blue            SUV_ny           blue_ny  \n","4     mid-size_ca           sedan_red          sedan_ca            red_ca  \n","\n","[5 rows x 94 columns]"],"text/html":["\n","  <div id=\"df-4fe8716e-8c62-4a59-96d2-c7b5c589a4cb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>drive_size</th>\n","      <th>drive_type</th>\n","      <th>drive_paint_color</th>\n","      <th>drive_state</th>\n","      <th>size_type</th>\n","      <th>size_paint_color</th>\n","      <th>size_state</th>\n","      <th>type_paint_color</th>\n","      <th>type_state</th>\n","      <th>paint_color_state</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nashville</td>\n","      <td>1949</td>\n","      <td>bmw</td>\n","      <td>excellent</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>115148</td>\n","      <td>clean</td>\n","      <td>manual</td>\n","      <td>rwd</td>\n","      <td>...</td>\n","      <td>rwd_mid-size</td>\n","      <td>rwd_convertible</td>\n","      <td>rwd_orange</td>\n","      <td>rwd_none</td>\n","      <td>mid-size_convertible</td>\n","      <td>mid-size_orange</td>\n","      <td>mid-size_none</td>\n","      <td>convertible_orange</td>\n","      <td>convertible_none</td>\n","      <td>orange_none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>state college</td>\n","      <td>2013</td>\n","      <td>toyota</td>\n","      <td>fair</td>\n","      <td>8 cylinders</td>\n","      <td>gas</td>\n","      <td>172038</td>\n","      <td>clean</td>\n","      <td>automatic</td>\n","      <td>rwd</td>\n","      <td>...</td>\n","      <td>rwd_full-size</td>\n","      <td>rwd_sedan</td>\n","      <td>rwd_silver</td>\n","      <td>rwd_pa</td>\n","      <td>full-size_sedan</td>\n","      <td>full-size_silver</td>\n","      <td>full-size_pa</td>\n","      <td>sedan_silver</td>\n","      <td>sedan_pa</td>\n","      <td>silver_pa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wichita</td>\n","      <td>1998</td>\n","      <td>ford</td>\n","      <td>good</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>152492</td>\n","      <td>clean</td>\n","      <td>automatic</td>\n","      <td>fwd</td>\n","      <td>...</td>\n","      <td>fwd_full-size</td>\n","      <td>fwd_SUV</td>\n","      <td>fwd_silver</td>\n","      <td>fwd_ks</td>\n","      <td>full-size_SUV</td>\n","      <td>full-size_silver</td>\n","      <td>full-size_ks</td>\n","      <td>SUV_silver</td>\n","      <td>SUV_ks</td>\n","      <td>silver_ks</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>albany</td>\n","      <td>2014</td>\n","      <td>ford</td>\n","      <td>excellent</td>\n","      <td>4 cylinders</td>\n","      <td>gas</td>\n","      <td>104118</td>\n","      <td>clean</td>\n","      <td>manual</td>\n","      <td>fwd</td>\n","      <td>...</td>\n","      <td>fwd_mid-size</td>\n","      <td>fwd_SUV</td>\n","      <td>fwd_blue</td>\n","      <td>fwd_ny</td>\n","      <td>mid-size_SUV</td>\n","      <td>mid-size_blue</td>\n","      <td>mid-size_ny</td>\n","      <td>SUV_blue</td>\n","      <td>SUV_ny</td>\n","      <td>blue_ny</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>redding</td>\n","      <td>2005</td>\n","      <td>ford</td>\n","      <td>excellent</td>\n","      <td>6 cylinders</td>\n","      <td>gas</td>\n","      <td>144554</td>\n","      <td>clean</td>\n","      <td>manual</td>\n","      <td>fwd</td>\n","      <td>...</td>\n","      <td>fwd_mid-size</td>\n","      <td>fwd_sedan</td>\n","      <td>fwd_red</td>\n","      <td>fwd_ca</td>\n","      <td>mid-size_sedan</td>\n","      <td>mid-size_red</td>\n","      <td>mid-size_ca</td>\n","      <td>sedan_red</td>\n","      <td>sedan_ca</td>\n","      <td>red_ca</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 94 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fe8716e-8c62-4a59-96d2-c7b5c589a4cb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4fe8716e-8c62-4a59-96d2-c7b5c589a4cb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4fe8716e-8c62-4a59-96d2-c7b5c589a4cb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5dc35e65-8081-48a5-8fab-2af999708444\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5dc35e65-8081-48a5-8fab-2af999708444')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5dc35e65-8081-48a5-8fab-2af999708444 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Initialize a dictionary to store label encoders for each categorical variable\n","label_encoders = {}\n","categorical_vars=categorical_features\n","for var in categorical_vars:\n","    le = LabelEncoder()\n","\n","    # Fit the encoder on the combined data to ensure all categories are captured\n","    combined_data = pd.concat([X[var], X_new_test[var]], axis=0).astype(str)\n","    le.fit(combined_data)\n","\n","    # Transform the training and test data\n","    X[var] = le.transform(X[var].astype(str))\n","    X_new_test[var] = le.transform(X_new_test[var].astype(str))\n","\n","    # Store the encoder for potential use later\n","    label_encoders[var] = le\n","\n","X.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"woiJZVK-jbDk","executionInfo":{"status":"ok","timestamp":1692540539976,"user_tz":-540,"elapsed":3063,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"34923f29-95c8-4140-a84d-a44e6bac1122"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    region  year  manufacturer  condition  cylinders  fuel  odometer  \\\n","id                                                                     \n","0      215  1949            39          0          5     2    115148   \n","1      321  2013            72          1          6     2    172038   \n","2      358  1998            46          2          5     2    152492   \n","3        3  2014            46          0          3     2    104118   \n","4      264  2005            46          0          5     2    144554   \n","\n","    title_status  transmission  drive  ...  drive_size  drive_type  \\\n","id                                     ...                           \n","0              0             1      2  ...          21          30   \n","1              0             0      2  ...          18          38   \n","2              0             0      1  ...           9          14   \n","3              0             1      1  ...          12          14   \n","4              0             1      1  ...          12          24   \n","\n","    drive_paint_color  drive_state  size_type  size_paint_color  size_state  \\\n","id                                                                            \n","0                  30          137         46                46         191   \n","1                  33          143         24                21          91   \n","2                  21           68         14                21          68   \n","3                  13           87         44                41         193   \n","4                  20           56         54                48         162   \n","\n","    type_paint_color  type_state  paint_color_state  \n","id                                                   \n","0                 25         100                329  \n","1                117         488                457  \n","2                  9          16                434  \n","3                  1          35                 87  \n","4                116         453                370  \n","\n","[5 rows x 94 columns]"],"text/html":["\n","  <div id=\"df-e4679537-780c-4557-9b95-cf7a378b845e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>drive_size</th>\n","      <th>drive_type</th>\n","      <th>drive_paint_color</th>\n","      <th>drive_state</th>\n","      <th>size_type</th>\n","      <th>size_paint_color</th>\n","      <th>size_state</th>\n","      <th>type_paint_color</th>\n","      <th>type_state</th>\n","      <th>paint_color_state</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>215</td>\n","      <td>1949</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>115148</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>137</td>\n","      <td>46</td>\n","      <td>46</td>\n","      <td>191</td>\n","      <td>25</td>\n","      <td>100</td>\n","      <td>329</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>321</td>\n","      <td>2013</td>\n","      <td>72</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>172038</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>38</td>\n","      <td>33</td>\n","      <td>143</td>\n","      <td>24</td>\n","      <td>21</td>\n","      <td>91</td>\n","      <td>117</td>\n","      <td>488</td>\n","      <td>457</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>358</td>\n","      <td>1998</td>\n","      <td>46</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>152492</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>14</td>\n","      <td>21</td>\n","      <td>68</td>\n","      <td>14</td>\n","      <td>21</td>\n","      <td>68</td>\n","      <td>9</td>\n","      <td>16</td>\n","      <td>434</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2014</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>104118</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>12</td>\n","      <td>14</td>\n","      <td>13</td>\n","      <td>87</td>\n","      <td>44</td>\n","      <td>41</td>\n","      <td>193</td>\n","      <td>1</td>\n","      <td>35</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>264</td>\n","      <td>2005</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>144554</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>12</td>\n","      <td>24</td>\n","      <td>20</td>\n","      <td>56</td>\n","      <td>54</td>\n","      <td>48</td>\n","      <td>162</td>\n","      <td>116</td>\n","      <td>453</td>\n","      <td>370</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 94 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4679537-780c-4557-9b95-cf7a378b845e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e4679537-780c-4557-9b95-cf7a378b845e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e4679537-780c-4557-9b95-cf7a378b845e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-19e5234f-d648-442b-ae0c-4d87277d277c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19e5234f-d648-442b-ae0c-4d87277d277c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-19e5234f-d648-442b-ae0c-4d87277d277c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["X_new_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"jDaaPsA0PWAk","executionInfo":{"status":"ok","timestamp":1692540539979,"user_tz":-540,"elapsed":19,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"d8276924-1501-425a-d80a-fc6a915a13b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       region  year  manufacturer  condition  cylinders  fuel  odometer  \\\n","id                                                                        \n","27532     357  2015            42          0          3     2     92553   \n","27533     271  2013            63          3          3     2    134385   \n","27534       2  2011            74          2          3     2    102489   \n","27535      74  2016            52          0          5     0     64310   \n","27536     134  1999            48          0          6     2    180839   \n","...       ...   ...           ...        ...        ...   ...       ...   \n","55064     121  2016            47          0          5     2     90902   \n","55065     174  2012            63          0          3     2     27234   \n","55066     251  2002            39          0          5     2     99761   \n","55067      60  2006            39          0          5     2    162279   \n","55068     325  2006            52          0          5     2    186965   \n","\n","       title_status  transmission  drive  ...  drive_size  drive_type  \\\n","id                                        ...                           \n","27532             0             0      1  ...           9          14   \n","27533             6             0      1  ...          12          24   \n","27534             0             0      1  ...           9          24   \n","27535             0             0      0  ...           4           0   \n","27536             5             0      0  ...           4           0   \n","...             ...           ...    ...  ...         ...         ...   \n","55064             5             0      1  ...           9          25   \n","55065             5             0      1  ...          12          24   \n","55066             0             0      2  ...          18          31   \n","55067             0             0      0  ...           4          10   \n","55068             0             0      0  ...           1           0   \n","\n","       drive_paint_color  drive_state  size_type  size_paint_color  \\\n","id                                                                   \n","27532                 20           85         14                20   \n","27533                 12           90         54                40   \n","27534                 12           88         24                12   \n","27535                  8            5         44                48   \n","27536                  9           27         44                49   \n","...                  ...          ...        ...               ...   \n","55064                 12           78         25                12   \n","55065                 22           86         54                50   \n","55066                 25          107         17                13   \n","55067                  9            5         54                49   \n","55068                  0           35         14                12   \n","\n","       size_state  type_paint_color  type_state  paint_color_state  \n","id                                                                  \n","27532          85                 8          33                399  \n","27533         196               108         487                 38  \n","27534          88               108         485                 36  \n","27535         163                 8           5                371  \n","27536         185                 9          27                445  \n","...           ...               ...         ...                ...  \n","55064          78               120         527                 26  \n","55065         192               118         483                504  \n","55066          55                32         120                 55  \n","55067         163               117         454                423  \n","55068          87                 0          35                 35  \n","\n","[27537 rows x 94 columns]"],"text/html":["\n","  <div id=\"df-df68f1de-00d0-4255-a271-1938d8b989e6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>drive_size</th>\n","      <th>drive_type</th>\n","      <th>drive_paint_color</th>\n","      <th>drive_state</th>\n","      <th>size_type</th>\n","      <th>size_paint_color</th>\n","      <th>size_state</th>\n","      <th>type_paint_color</th>\n","      <th>type_state</th>\n","      <th>paint_color_state</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27532</th>\n","      <td>357</td>\n","      <td>2015</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>92553</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>85</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>85</td>\n","      <td>8</td>\n","      <td>33</td>\n","      <td>399</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>271</td>\n","      <td>2013</td>\n","      <td>63</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>134385</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>12</td>\n","      <td>24</td>\n","      <td>12</td>\n","      <td>90</td>\n","      <td>54</td>\n","      <td>40</td>\n","      <td>196</td>\n","      <td>108</td>\n","      <td>487</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>27534</th>\n","      <td>2</td>\n","      <td>2011</td>\n","      <td>74</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>102489</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>24</td>\n","      <td>12</td>\n","      <td>88</td>\n","      <td>24</td>\n","      <td>12</td>\n","      <td>88</td>\n","      <td>108</td>\n","      <td>485</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>27535</th>\n","      <td>74</td>\n","      <td>2016</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>64310</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>44</td>\n","      <td>48</td>\n","      <td>163</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>371</td>\n","    </tr>\n","    <tr>\n","      <th>27536</th>\n","      <td>134</td>\n","      <td>1999</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>180839</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>44</td>\n","      <td>49</td>\n","      <td>185</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>445</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>55064</th>\n","      <td>121</td>\n","      <td>2016</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>90902</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>25</td>\n","      <td>12</td>\n","      <td>78</td>\n","      <td>25</td>\n","      <td>12</td>\n","      <td>78</td>\n","      <td>120</td>\n","      <td>527</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>55065</th>\n","      <td>174</td>\n","      <td>2012</td>\n","      <td>63</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>27234</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>12</td>\n","      <td>24</td>\n","      <td>22</td>\n","      <td>86</td>\n","      <td>54</td>\n","      <td>50</td>\n","      <td>192</td>\n","      <td>118</td>\n","      <td>483</td>\n","      <td>504</td>\n","    </tr>\n","    <tr>\n","      <th>55066</th>\n","      <td>251</td>\n","      <td>2002</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>99761</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>31</td>\n","      <td>25</td>\n","      <td>107</td>\n","      <td>17</td>\n","      <td>13</td>\n","      <td>55</td>\n","      <td>32</td>\n","      <td>120</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>55067</th>\n","      <td>60</td>\n","      <td>2006</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>162279</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>54</td>\n","      <td>49</td>\n","      <td>163</td>\n","      <td>117</td>\n","      <td>454</td>\n","      <td>423</td>\n","    </tr>\n","    <tr>\n","      <th>55068</th>\n","      <td>325</td>\n","      <td>2006</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>186965</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>14</td>\n","      <td>12</td>\n","      <td>87</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>35</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27537 rows × 94 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df68f1de-00d0-4255-a271-1938d8b989e6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-df68f1de-00d0-4255-a271-1938d8b989e6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-df68f1de-00d0-4255-a271-1938d8b989e6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ce41e873-a8e5-4e12-9845-5000bf1a3e7c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce41e873-a8e5-4e12-9845-5000bf1a3e7c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ce41e873-a8e5-4e12-9845-5000bf1a3e7c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# from sklearn.model_selection import train_test_split\n","# import xgboost as xgb\n","# from sklearn.linear_model import LinearRegression, Ridge\n","# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","# from sklearn.svm import SVR\n","# from sklearn.neural_network import MLPRegressor\n","# from sklearn.model_selection import KFold\n","# from sklearn.preprocessing import MinMaxScaler\n","# import numpy as np\n","# import pandas as pd\n","\n","# targets_for_encoding = ['price']\n","# # , 'odometer', 'year'\n","# def target_encode_with_multiple_targets(X,y):\n","#     # Copy the original data for target encoding\n","#     X_encoded = X.copy()\n","#     X_encoded['price'] = y\n","\n","#     # Apply target encoding and create new features for each categorical variable and target\n","#     for target in targets_for_encoding:\n","#         for var in categorical_vars:\n","#             # Calculate statistics for target encoding\n","#             target_mean = X_encoded.groupby(var)[target].mean()\n","#             target_min = X_encoded.groupby(var)[target].min()\n","#             target_max = X_encoded.groupby(var)[target].max()\n","\n","#             # Create new features with the calculated statistics\n","#             X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","#             # X_encoded[var + f'_{target}_min_enc'] = X_encoded[var].map(target_min)\n","#             X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","#     X_encoded.drop('price', axis=1, inplace=True)\n","\n","#     return X_encoded\n","\n","# def target_encode_evaluation_data_with_multiple_targets(X_eval, X_train, y_train):\n","#     # Copy the evaluation data for target encoding\n","#     X_encoded_eval = X_eval.copy()\n","\n","#     # Add 'price' to training data for target encoding calculations\n","#     X_train_encoded = X_train.copy()\n","#     X_train_encoded['price'] = y_train\n","\n","#     # Apply target encoding using statistics from the TRAINING data\n","#     for target in targets_for_encoding:\n","#         for var in categorical_vars:\n","#             # Calculate statistics for target encoding using TRAINING data\n","#             target_mean = X_train_encoded.groupby(var)[target].mean()\n","#             target_min = X_train_encoded.groupby(var)[target].min()\n","#             target_max = X_train_encoded.groupby(var)[target].max()\n","\n","#             # Apply the calculated statistics to the EVALUATION data\n","#             X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","#             # X_encoded_eval[var + f'_{target}_min_enc'] = X_encoded_eval[var].map(target_min)\n","#             X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","\n","#     # Handle any NaN values which might occur if there's a new category in evaluation data\n","#     X_encoded_eval.fillna(X_train_encoded.mean(), inplace=True)\n","\n","#     return X_encoded_eval\n","\n","# # Apply target encoding to the full dataset\n","# #X_encoded = target_encode_full_data(X, y)\n","# X_train_scaled =target_encode_with_multiple_targets(X,y)\n","# X_test_scaled=target_encode_evaluation_data_with_multiple_targets(X_new_test,X,y)\n","# # Split the encoded data into training and test sets (30% of the data will be used for testing)\n","# # X_train_encoded, X_test_encoded, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n","\n","# # Select only numeric columns for scaling\n","# # X_train_encoded_numeric = X_train_encoded.select_dtypes(include=[np.number])\n","# # X_test_encoded_numeric = X_test_encoded.select_dtypes(include=[np.number])\n","\n","# # Scaling\n","# # scaler = MinMaxScaler()\n","# # X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_encoded_numeric), columns=X_train_encoded_numeric.columns)\n","# # X_test_scaled = pd.DataFrame(scaler.transform(X_test_encoded_numeric), columns=X_test_encoded_numeric.columns)\n","# # X_train_scaled=X_train_encoded_numeric\n","# # X_test_scaled=X_test_encoded_numeric\n","# X_train_scaled, X_traintest_scaled, y_train, y_test = train_test_split(X_train_scaled, y, test_size=0.3, random_state=42)"],"metadata":{"id":"jzQSwwb7_aoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_all= pd.concat([X, X_new_test], axis=0)"],"metadata":{"id":"cbUBZKbV__Cq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","from sklearn.linear_model import LinearRegression, Ridge\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.svm import SVR\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","import pandas as pd\n","\n","# 1. 'price' のターゲットエンコーディング用に変数を設定\n","targets_for_price = ['price']\n","targets_for_encoding = ['price']\n","# 2. 'all' からの他のターゲットエンコーディング用に変数を設定\n","targets_for_all = ['odometer', 'year']\n","\n","def target_encode_with_specified_targets(X, y, targets):\n","    X_encoded = X.copy()\n","    X_encoded['price'] = y\n","\n","    # Apply target encoding and create new features for each categorical variable and target\n","    for target in targets:\n","        for var in categorical_vars:\n","            # Calculate statistics for target encoding\n","            target_mean = X_encoded.groupby(var)[target].mean()\n","            target_min = X_encoded.groupby(var)[target].min()\n","            target_max = X_encoded.groupby(var)[target].max()\n","\n","            # Create new features with the calculated statistics\n","            X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","            X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","\n","    X_encoded.drop('price', axis=1, inplace=True)\n","    return X_encoded\n","\n","def target_encode_evaluation_data_with_multiple_targets(X_eval, X_train, y_train):\n","    # Copy the evaluation data for target encoding\n","    X_encoded_eval = X_eval.copy()\n","\n","    # Add 'price' to training data for target encoding calculations\n","    X_train_encoded = X_train.copy()\n","    X_train_encoded['price'] = y_train\n","\n","    # Apply target encoding using statistics from the TRAINING data\n","    for target in targets_for_encoding:\n","        for var in categorical_vars:\n","            # Calculate statistics for target encoding using TRAINING data\n","            target_mean = X_train_encoded.groupby(var)[target].mean()\n","            target_max = X_train_encoded.groupby(var)[target].max()\n","\n","            # Apply the calculated statistics to the EVALUATION data\n","            X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","            X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","\n","    # Handle any NaN values which might occur if there's a new category in evaluation data\n","    X_encoded_eval.fillna(X_train_encoded.mean(), inplace=True)\n","    return X_encoded_eval\n","\n","\n","# Apply target encoding to X using statistics from itself\n","X_encoded_from_X = target_encode_with_specified_targets(X, y, targets_for_price)\n","\n","# Apply target encoding to X again using statistics from X_all\n","X_encoded_from_all = target_encode_evaluation_data_with_multiple_targets(X, X_all, y)\n","\n","# Combine both encoded data for X\n","X_combined_encoded = pd.concat([X_encoded_from_X, X_encoded_from_all], axis=1)\n","\n","\n","X_new_test_encoded_from_X = target_encode_evaluation_data_with_multiple_targets(X_new_test, X, y)\n","\n","# Apply target encoding to X_new_test using statistics from X_all and y for 'odometer' and 'year'\n","X_new_test_encoded_from_all = target_encode_evaluation_data_with_multiple_targets(X_new_test, X_all, y)\n","\n","# Combine both encoded test data\n","X_new_test_combined_encoded = pd.concat([X_new_test_encoded_from_X, X_new_test_encoded_from_all], axis=1)\n","\n","X_new_test_combined_encoded.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ebW54MjZwX9q","executionInfo":{"status":"ok","timestamp":1692540543527,"user_tz":-540,"elapsed":3562,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"33de6fc8-8451-4496-a4e6-f15da708b3cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_mean_enc'] = X_encoded[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded[var + f'_{target}_max_enc'] = X_encoded[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n","<ipython-input-47-f1f7075dd6f6>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_mean_enc'] = X_encoded_eval[var].map(target_mean)\n","<ipython-input-47-f1f7075dd6f6>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_encoded_eval[var + f'_{target}_max_enc'] = X_encoded_eval[var].map(target_max)\n"]},{"output_type":"execute_result","data":{"text/plain":["       region  year  manufacturer  condition  cylinders  fuel  odometer  \\\n","id                                                                        \n","27532     357  2015            42          0          3     2     92553   \n","27533     271  2013            63          3          3     2    134385   \n","27534       2  2011            74          2          3     2    102489   \n","27535      74  2016            52          0          5     0     64310   \n","27536     134  1999            48          0          6     2    180839   \n","\n","       title_status  transmission  drive  ...  \\\n","id                                        ...   \n","27532             0             0      1  ...   \n","27533             6             0      1  ...   \n","27534             0             0      1  ...   \n","27535             0             0      0  ...   \n","27536             5             0      0  ...   \n","\n","       size_paint_color_price_mean_enc  size_paint_color_price_max_enc  \\\n","id                                                                       \n","27532                         9.226448                       11.480599   \n","27533                         9.274698                       11.196967   \n","27534                         9.427975                       11.400977   \n","27535                         8.980289                       10.955899   \n","27536                         9.030135                       11.095818   \n","\n","       size_state_price_mean_enc  size_state_price_max_enc  \\\n","id                                                           \n","27532                   9.330922                 11.400977   \n","27533                   9.120814                 10.853909   \n","27534                   9.185139                 11.273221   \n","27535                   9.150509                 10.821237   \n","27536                   9.097225                 11.087421   \n","\n","       type_paint_color_price_mean_enc  type_paint_color_price_max_enc  \\\n","id                                                                       \n","27532                         9.059561                       11.480599   \n","27533                         9.056116                       11.131680   \n","27534                         9.056116                       11.131680   \n","27535                         9.059561                       11.480599   \n","27536                         9.096323                       11.095818   \n","\n","       type_state_price_mean_enc  type_state_price_max_enc  \\\n","id                                                           \n","27532                   9.248722                 11.146849   \n","27533                   8.937455                 10.853909   \n","27534                   8.890560                 10.624906   \n","27535                   9.268791                 10.883992   \n","27536                   9.243937                 11.087421   \n","\n","       paint_color_state_price_mean_enc  paint_color_state_price_max_enc  \n","id                                                                        \n","27532                          9.119626                        11.096652  \n","27533                          9.296213                        11.267306  \n","27534                          9.152396                        11.273221  \n","27535                          9.083048                        10.550119  \n","27536                          8.912066                        10.834194  \n","\n","[5 rows x 552 columns]"],"text/html":["\n","  <div id=\"df-2c128b3e-fa5f-4add-9acd-5bb305008b3a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>size_paint_color_price_mean_enc</th>\n","      <th>size_paint_color_price_max_enc</th>\n","      <th>size_state_price_mean_enc</th>\n","      <th>size_state_price_max_enc</th>\n","      <th>type_paint_color_price_mean_enc</th>\n","      <th>type_paint_color_price_max_enc</th>\n","      <th>type_state_price_mean_enc</th>\n","      <th>type_state_price_max_enc</th>\n","      <th>paint_color_state_price_mean_enc</th>\n","      <th>paint_color_state_price_max_enc</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27532</th>\n","      <td>357</td>\n","      <td>2015</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>92553</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.226448</td>\n","      <td>11.480599</td>\n","      <td>9.330922</td>\n","      <td>11.400977</td>\n","      <td>9.059561</td>\n","      <td>11.480599</td>\n","      <td>9.248722</td>\n","      <td>11.146849</td>\n","      <td>9.119626</td>\n","      <td>11.096652</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>271</td>\n","      <td>2013</td>\n","      <td>63</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>134385</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.274698</td>\n","      <td>11.196967</td>\n","      <td>9.120814</td>\n","      <td>10.853909</td>\n","      <td>9.056116</td>\n","      <td>11.131680</td>\n","      <td>8.937455</td>\n","      <td>10.853909</td>\n","      <td>9.296213</td>\n","      <td>11.267306</td>\n","    </tr>\n","    <tr>\n","      <th>27534</th>\n","      <td>2</td>\n","      <td>2011</td>\n","      <td>74</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>102489</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.427975</td>\n","      <td>11.400977</td>\n","      <td>9.185139</td>\n","      <td>11.273221</td>\n","      <td>9.056116</td>\n","      <td>11.131680</td>\n","      <td>8.890560</td>\n","      <td>10.624906</td>\n","      <td>9.152396</td>\n","      <td>11.273221</td>\n","    </tr>\n","    <tr>\n","      <th>27535</th>\n","      <td>74</td>\n","      <td>2016</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>64310</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>8.980289</td>\n","      <td>10.955899</td>\n","      <td>9.150509</td>\n","      <td>10.821237</td>\n","      <td>9.059561</td>\n","      <td>11.480599</td>\n","      <td>9.268791</td>\n","      <td>10.883992</td>\n","      <td>9.083048</td>\n","      <td>10.550119</td>\n","    </tr>\n","    <tr>\n","      <th>27536</th>\n","      <td>134</td>\n","      <td>1999</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>180839</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.030135</td>\n","      <td>11.095818</td>\n","      <td>9.097225</td>\n","      <td>11.087421</td>\n","      <td>9.096323</td>\n","      <td>11.095818</td>\n","      <td>9.243937</td>\n","      <td>11.087421</td>\n","      <td>8.912066</td>\n","      <td>10.834194</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 552 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c128b3e-fa5f-4add-9acd-5bb305008b3a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2c128b3e-fa5f-4add-9acd-5bb305008b3a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2c128b3e-fa5f-4add-9acd-5bb305008b3a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-91dfbb20-4585-42e4-b1ee-ae77e1cebca3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91dfbb20-4585-42e4-b1ee-ae77e1cebca3')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-91dfbb20-4585-42e4-b1ee-ae77e1cebca3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["X_combined_encoded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"e83Cn94edvYW","executionInfo":{"status":"ok","timestamp":1692540078997,"user_tz":-540,"elapsed":321,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"862d96ae-c58f-45d9-e9fc-9ef7d3c9e12a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       region  year  manufacturer  condition  cylinders  fuel  odometer  \\\n","id                                                                        \n","0         215  1949            39          0          5     2    115148   \n","1         321  2013            72          1          6     2    172038   \n","2         358  1998            46          2          5     2    152492   \n","3           3  2014            46          0          3     2    104118   \n","4         264  2005            46          0          5     2    144554   \n","...       ...   ...           ...        ...        ...   ...       ...   \n","27527     360  2008            46          2          5     2     26660   \n","27528     337  2007            46          0          6     2    108072   \n","27529     269  2019            52          3          5     2    139908   \n","27530     269  2007            52          0          5     2    112326   \n","27531     242  2009            42          0          6     2     91813   \n","\n","       title_status  transmission  drive  ...  \\\n","id                                        ...   \n","0                 0             1      2  ...   \n","1                 0             0      2  ...   \n","2                 0             0      1  ...   \n","3                 0             1      1  ...   \n","4                 0             1      1  ...   \n","...             ...           ...    ...  ...   \n","27527             0             0      2  ...   \n","27528             0             0      2  ...   \n","27529             0             0      0  ...   \n","27530             0             0      0  ...   \n","27531             5             0      2  ...   \n","\n","       transmission_size_price_mean_enc  transmission_size_price_max_enc  \\\n","id                                                                         \n","0                              9.002582                        11.169801   \n","1                              9.359863                        11.480599   \n","2                              9.359863                        11.480599   \n","3                              9.002582                        11.169801   \n","4                              9.002582                        11.169801   \n","...                                 ...                              ...   \n","27527                          8.919402                        10.969353   \n","27528                          9.359863                        11.480599   \n","27529                          9.196960                        11.302353   \n","27530                          9.196960                        11.302353   \n","27531                          9.359863                        11.480599   \n","\n","       transmission_type_price_mean_enc  transmission_type_price_max_enc  \\\n","id                                                                         \n","0                              9.210240                        10.781287   \n","1                              9.007278                        11.201074   \n","2                              9.309844                        11.480599   \n","3                              9.049841                        11.273221   \n","4                              8.793447                        11.146027   \n","...                                 ...                              ...   \n","27527                          9.678240                        11.465100   \n","27528                          9.618981                        11.400977   \n","27529                          9.309844                        11.480599   \n","27530                          9.007278                        11.201074   \n","27531                          9.347804                        11.265707   \n","\n","       drive_size_price_mean_enc  drive_size_price_max_enc  \\\n","id                                                           \n","0                       9.436102                 11.302353   \n","1                       9.373652                 11.318369   \n","2                       8.939408                 11.176921   \n","3                       9.015053                 11.169801   \n","4                       9.015053                 11.169801   \n","...                          ...                       ...   \n","27527                   9.207698                 10.887979   \n","27528                   9.373652                 11.318369   \n","27529                   9.464871                 11.280665   \n","27530                   9.464871                 11.280665   \n","27531                   9.373652                 11.318369   \n","\n","       drive_type_price_mean_enc  drive_type_price_max_enc  \\\n","id                                                           \n","0                       9.366915                 10.843475   \n","1                       9.264435                 11.201074   \n","2                       9.048696                 10.969353   \n","3                       9.048696                 10.969353   \n","4                       8.917410                 10.942385   \n","...                          ...                       ...   \n","27527                   9.542093                 11.290582   \n","27528                   9.442330                 11.318369   \n","27529                   9.442506                 11.480599   \n","27530                   9.269472                 11.131680   \n","27531                   9.552860                 11.128615   \n","\n","       size_type_price_mean_enc  size_type_price_max_enc  \n","id                                                        \n","0                      9.363252                10.818157  \n","1                      8.955201                11.201074  \n","2                      9.290272                11.480599  \n","3                      9.262217                11.302353  \n","4                      9.042572                11.131680  \n","...                         ...                      ...  \n","27527                  9.078606                10.380125  \n","27528                  9.581019                11.400977  \n","27529                  9.262217                11.302353  \n","27530                  9.042572                11.131680  \n","27531                  9.342287                11.265707  \n","\n","[27532 rows x 354 columns]"],"text/html":["\n","  <div id=\"df-8568487a-6a48-4e87-880b-90b93ce83282\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>transmission_size_price_mean_enc</th>\n","      <th>transmission_size_price_max_enc</th>\n","      <th>transmission_type_price_mean_enc</th>\n","      <th>transmission_type_price_max_enc</th>\n","      <th>drive_size_price_mean_enc</th>\n","      <th>drive_size_price_max_enc</th>\n","      <th>drive_type_price_mean_enc</th>\n","      <th>drive_type_price_max_enc</th>\n","      <th>size_type_price_mean_enc</th>\n","      <th>size_type_price_max_enc</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>215</td>\n","      <td>1949</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>115148</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.002582</td>\n","      <td>11.169801</td>\n","      <td>9.210240</td>\n","      <td>10.781287</td>\n","      <td>9.436102</td>\n","      <td>11.302353</td>\n","      <td>9.366915</td>\n","      <td>10.843475</td>\n","      <td>9.363252</td>\n","      <td>10.818157</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>321</td>\n","      <td>2013</td>\n","      <td>72</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>172038</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.373652</td>\n","      <td>11.318369</td>\n","      <td>9.264435</td>\n","      <td>11.201074</td>\n","      <td>8.955201</td>\n","      <td>11.201074</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>358</td>\n","      <td>1998</td>\n","      <td>46</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>152492</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>9.048696</td>\n","      <td>10.969353</td>\n","      <td>9.290272</td>\n","      <td>11.480599</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2014</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>104118</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.002582</td>\n","      <td>11.169801</td>\n","      <td>9.049841</td>\n","      <td>11.273221</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>9.048696</td>\n","      <td>10.969353</td>\n","      <td>9.262217</td>\n","      <td>11.302353</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>264</td>\n","      <td>2005</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>144554</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.002582</td>\n","      <td>11.169801</td>\n","      <td>8.793447</td>\n","      <td>11.146027</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27527</th>\n","      <td>360</td>\n","      <td>2008</td>\n","      <td>46</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>26660</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>8.919402</td>\n","      <td>10.969353</td>\n","      <td>9.678240</td>\n","      <td>11.465100</td>\n","      <td>9.207698</td>\n","      <td>10.887979</td>\n","      <td>9.542093</td>\n","      <td>11.290582</td>\n","      <td>9.078606</td>\n","      <td>10.380125</td>\n","    </tr>\n","    <tr>\n","      <th>27528</th>\n","      <td>337</td>\n","      <td>2007</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>108072</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.618981</td>\n","      <td>11.400977</td>\n","      <td>9.373652</td>\n","      <td>11.318369</td>\n","      <td>9.442330</td>\n","      <td>11.318369</td>\n","      <td>9.581019</td>\n","      <td>11.400977</td>\n","    </tr>\n","    <tr>\n","      <th>27529</th>\n","      <td>269</td>\n","      <td>2019</td>\n","      <td>52</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>139908</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.442506</td>\n","      <td>11.480599</td>\n","      <td>9.262217</td>\n","      <td>11.302353</td>\n","    </tr>\n","    <tr>\n","      <th>27530</th>\n","      <td>269</td>\n","      <td>2007</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>112326</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.269472</td>\n","      <td>11.131680</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>27531</th>\n","      <td>242</td>\n","      <td>2009</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>91813</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.347804</td>\n","      <td>11.265707</td>\n","      <td>9.373652</td>\n","      <td>11.318369</td>\n","      <td>9.552860</td>\n","      <td>11.128615</td>\n","      <td>9.342287</td>\n","      <td>11.265707</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27532 rows × 354 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8568487a-6a48-4e87-880b-90b93ce83282')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8568487a-6a48-4e87-880b-90b93ce83282 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8568487a-6a48-4e87-880b-90b93ce83282');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-359a7048-495e-4027-b65f-95d9fd812128\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-359a7048-495e-4027-b65f-95d9fd812128')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-359a7048-495e-4027-b65f-95d9fd812128 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["X_new_test_combined_encoded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"SWdwmRnEPJeX","executionInfo":{"status":"ok","timestamp":1692540062450,"user_tz":-540,"elapsed":24,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"ed670f33-3d4e-4bfc-b9d2-108354bfb101"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       region  year  manufacturer  condition  cylinders  fuel  odometer  \\\n","id                                                                        \n","27532     357  2015            42          0          3     2     92553   \n","27533     271  2013            63          3          3     2    134385   \n","27534       2  2011            74          2          3     2    102489   \n","27535      74  2016            52          0          5     0     64310   \n","27536     134  1999            48          0          6     2    180839   \n","...       ...   ...           ...        ...        ...   ...       ...   \n","55064     121  2016            47          0          5     2     90902   \n","55065     174  2012            63          0          3     2     27234   \n","55066     251  2002            39          0          5     2     99761   \n","55067      60  2006            39          0          5     2    162279   \n","55068     325  2006            52          0          5     2    186965   \n","\n","       title_status  transmission  drive  ...  \\\n","id                                        ...   \n","27532             0             0      1  ...   \n","27533             6             0      1  ...   \n","27534             0             0      1  ...   \n","27535             0             0      0  ...   \n","27536             5             0      0  ...   \n","...             ...           ...    ...  ...   \n","55064             5             0      1  ...   \n","55065             5             0      1  ...   \n","55066             0             0      2  ...   \n","55067             0             0      0  ...   \n","55068             0             0      0  ...   \n","\n","       transmission_size_price_mean_enc  transmission_size_price_max_enc  \\\n","id                                                                         \n","27532                          9.359863                        11.480599   \n","27533                          9.196960                        11.302353   \n","27534                          9.359863                        11.480599   \n","27535                          9.196960                        11.302353   \n","27536                          9.196960                        11.302353   \n","...                                 ...                              ...   \n","55064                          9.359863                        11.480599   \n","55065                          9.196960                        11.302353   \n","55066                          9.359863                        11.480599   \n","55067                          9.196960                        11.302353   \n","55068                          9.359863                        11.480599   \n","\n","       transmission_type_price_mean_enc  transmission_type_price_max_enc  \\\n","id                                                                         \n","27532                          9.309844                        11.480599   \n","27533                          9.007278                        11.201074   \n","27534                          9.007278                        11.201074   \n","27535                          9.309844                        11.480599   \n","27536                          9.309844                        11.480599   \n","...                                 ...                              ...   \n","55064                          9.678240                        11.465100   \n","55065                          9.007278                        11.201074   \n","55066                          9.207098                        11.196967   \n","55067                          9.007278                        11.201074   \n","55068                          9.309844                        11.480599   \n","\n","       drive_size_price_mean_enc  drive_size_price_max_enc  \\\n","id                                                           \n","27532                   8.939408                 11.176921   \n","27533                   9.015053                 11.169801   \n","27534                   8.939408                 11.176921   \n","27535                   9.464871                 11.280665   \n","27536                   9.464871                 11.280665   \n","...                          ...                       ...   \n","55064                   8.939408                 11.176921   \n","55065                   9.015053                 11.169801   \n","55066                   9.373652                 11.318369   \n","55067                   9.464871                 11.280665   \n","55068                   9.605630                 11.480599   \n","\n","       drive_type_price_mean_enc  drive_type_price_max_enc  \\\n","id                                                           \n","27532                   9.048696                 10.969353   \n","27533                   8.917410                 10.942385   \n","27534                   8.917410                 10.942385   \n","27535                   9.442506                 11.480599   \n","27536                   9.442506                 11.480599   \n","...                          ...                       ...   \n","55064                   9.060004                 10.849240   \n","55065                   8.917410                 10.942385   \n","55066                   9.273507                 11.196967   \n","55067                   9.269472                 11.131680   \n","55068                   9.442506                 11.480599   \n","\n","       size_type_price_mean_enc  size_type_price_max_enc  \n","id                                                        \n","27532                  9.290272                11.480599  \n","27533                  9.042572                11.131680  \n","27534                  8.955201                11.201074  \n","27535                  9.262217                11.302353  \n","27536                  9.262217                11.302353  \n","...                         ...                      ...  \n","55064                  9.638499                11.465100  \n","55065                  9.042572                11.131680  \n","55066                  9.101938                11.156222  \n","55067                  9.042572                11.131680  \n","55068                  9.290272                11.480599  \n","\n","[27537 rows x 354 columns]"],"text/html":["\n","  <div id=\"df-83a6711c-cb1b-43fd-8e74-7cfcd8b5c17f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>transmission_size_price_mean_enc</th>\n","      <th>transmission_size_price_max_enc</th>\n","      <th>transmission_type_price_mean_enc</th>\n","      <th>transmission_type_price_max_enc</th>\n","      <th>drive_size_price_mean_enc</th>\n","      <th>drive_size_price_max_enc</th>\n","      <th>drive_type_price_mean_enc</th>\n","      <th>drive_type_price_max_enc</th>\n","      <th>size_type_price_mean_enc</th>\n","      <th>size_type_price_max_enc</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27532</th>\n","      <td>357</td>\n","      <td>2015</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>92553</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>9.048696</td>\n","      <td>10.969353</td>\n","      <td>9.290272</td>\n","      <td>11.480599</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>271</td>\n","      <td>2013</td>\n","      <td>63</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>134385</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>27534</th>\n","      <td>2</td>\n","      <td>2011</td>\n","      <td>74</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>102489</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>8.955201</td>\n","      <td>11.201074</td>\n","    </tr>\n","    <tr>\n","      <th>27535</th>\n","      <td>74</td>\n","      <td>2016</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>64310</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.442506</td>\n","      <td>11.480599</td>\n","      <td>9.262217</td>\n","      <td>11.302353</td>\n","    </tr>\n","    <tr>\n","      <th>27536</th>\n","      <td>134</td>\n","      <td>1999</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>180839</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.442506</td>\n","      <td>11.480599</td>\n","      <td>9.262217</td>\n","      <td>11.302353</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>55064</th>\n","      <td>121</td>\n","      <td>2016</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>90902</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.678240</td>\n","      <td>11.465100</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>9.060004</td>\n","      <td>10.849240</td>\n","      <td>9.638499</td>\n","      <td>11.465100</td>\n","    </tr>\n","    <tr>\n","      <th>55065</th>\n","      <td>174</td>\n","      <td>2012</td>\n","      <td>63</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>27234</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>55066</th>\n","      <td>251</td>\n","      <td>2002</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>99761</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.207098</td>\n","      <td>11.196967</td>\n","      <td>9.373652</td>\n","      <td>11.318369</td>\n","      <td>9.273507</td>\n","      <td>11.196967</td>\n","      <td>9.101938</td>\n","      <td>11.156222</td>\n","    </tr>\n","    <tr>\n","      <th>55067</th>\n","      <td>60</td>\n","      <td>2006</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>162279</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.269472</td>\n","      <td>11.131680</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>55068</th>\n","      <td>325</td>\n","      <td>2006</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>186965</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>9.605630</td>\n","      <td>11.480599</td>\n","      <td>9.442506</td>\n","      <td>11.480599</td>\n","      <td>9.290272</td>\n","      <td>11.480599</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27537 rows × 354 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83a6711c-cb1b-43fd-8e74-7cfcd8b5c17f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-83a6711c-cb1b-43fd-8e74-7cfcd8b5c17f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-83a6711c-cb1b-43fd-8e74-7cfcd8b5c17f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e582760e-4686-4df0-8c5a-7c26e175ed14\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e582760e-4686-4df0-8c5a-7c26e175ed14')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e582760e-4686-4df0-8c5a-7c26e175ed14 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# nan_train = X_train_scaled.isna().sum()\n","# nan_test = X_test_scaled.isna().sum()\n","\n","# print(\"NaN values in X_train_scaled:\")\n","# print(nan_train[nan_train > 0])  # Only columns with NaN values\n","\n","# print(\"\\nNaN values in X_test_scaled:\")\n","# print(nan_test[nan_test > 0])  # Only columns with NaN values\n"],"metadata":{"id":"4iS70rb3fzyN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_scaled, X_val_scaled, y_train, y_val_scaled= train_test_split(X_combined_encoded , y, test_size=0.3, random_state=42)\n","X_test_scaled=X_new_test_combined_encoded"],"metadata":{"id":"cBZullHMaWje"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_val_scaled"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"YqckbUsADTvA","executionInfo":{"status":"ok","timestamp":1692540400040,"user_tz":-540,"elapsed":9,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"906e9e85-5bbd-49cc-d050-609964b66495"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       region  year  manufacturer  condition  cylinders  fuel  odometer  \\\n","id                                                                        \n","21617     367  2006            48          0          3     2    156081   \n","21326     165  2008            58          1          3     2    143323   \n","5317      120  2016            68          0          6     0    130992   \n","19378      46  2005            48          1          3     2    131332   \n","2540      184  2000            39          0          3     2    126589   \n","...       ...   ...           ...        ...        ...   ...       ...   \n","4373      220  2014            74          3          3     2    123231   \n","19809     178  1997             9          1          6     2     45072   \n","5728      366  2007            46          0          5     2    252286   \n","8100      252  2007            40          0          5     2     91799   \n","3576      323  2014             2          0          5     2    108652   \n","\n","       title_status  transmission  drive  ...  \\\n","id                                        ...   \n","21617             0             1      1  ...   \n","21326             0             1      1  ...   \n","5317              0             0      0  ...   \n","19378             1             1      1  ...   \n","2540              0             1      2  ...   \n","...             ...           ...    ...  ...   \n","4373              5             0      1  ...   \n","19809             0             1      2  ...   \n","5728              0             0      1  ...   \n","8100              0             1      1  ...   \n","3576              0             0      2  ...   \n","\n","       transmission_size_price_mean_enc  transmission_size_price_max_enc  \\\n","id                                                                         \n","21617                          8.769920                        10.942385   \n","21326                          8.769920                        10.942385   \n","5317                           9.359863                        11.480599   \n","19378                          8.769920                        10.942385   \n","2540                           9.002582                        11.169801   \n","...                                 ...                              ...   \n","4373                           9.196960                        11.302353   \n","19809                          9.183054                        11.308616   \n","5728                           9.359863                        11.480599   \n","8100                           9.002582                        11.169801   \n","3576                           9.196960                        11.302353   \n","\n","       transmission_type_price_mean_enc  transmission_type_price_max_enc  \\\n","id                                                                         \n","21617                          8.793447                        11.146027   \n","21326                          8.793447                        11.146027   \n","5317                           9.678240                        11.465100   \n","19378                          8.879510                        11.107660   \n","2540                           8.793447                        11.146027   \n","...                                 ...                              ...   \n","4373                           9.007278                        11.201074   \n","19809                          9.484746                        11.290856   \n","5728                           9.007278                        11.201074   \n","8100                           8.879510                        11.107660   \n","3576                           9.007278                        11.201074   \n","\n","       drive_size_price_mean_enc  drive_size_price_max_enc  \\\n","id                                                           \n","21617                   8.831379                 10.969353   \n","21326                   8.831379                 10.969353   \n","5317                    9.605630                 11.480599   \n","19378                   8.831379                 10.969353   \n","2540                    9.436102                 11.302353   \n","...                          ...                       ...   \n","4373                    9.015053                 11.169801   \n","19809                   9.373652                 11.318369   \n","5728                    8.939408                 11.176921   \n","8100                    9.015053                 11.169801   \n","3576                    9.436102                 11.302353   \n","\n","       drive_type_price_mean_enc  drive_type_price_max_enc  \\\n","id                                                           \n","21617                   8.917410                 10.942385   \n","21326                   8.917410                 10.942385   \n","5317                    9.769985                 11.465100   \n","19378                   8.899706                 10.793660   \n","2540                    9.264435                 11.201074   \n","...                          ...                       ...   \n","4373                    8.917410                 10.942385   \n","19809                   9.542093                 11.290582   \n","5728                    8.917410                 10.942385   \n","8100                    8.899706                 10.793660   \n","3576                    9.264435                 11.201074   \n","\n","       size_type_price_mean_enc  size_type_price_max_enc  \n","id                                                        \n","21617                  8.838854                10.942385  \n","21326                  8.838854                10.942385  \n","5317                   9.638499                11.465100  \n","19378                  8.872018                10.747745  \n","2540                   9.042572                11.131680  \n","...                         ...                      ...  \n","4373                   9.042572                11.131680  \n","19809                  9.638499                11.465100  \n","5728                   8.955201                11.201074  \n","8100                   9.147297                11.196967  \n","3576                   9.042572                11.131680  \n","\n","[8260 rows x 354 columns]"],"text/html":["\n","  <div id=\"df-52e3c213-9713-4f22-8193-5d01d8a3e2e9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>transmission_size_price_mean_enc</th>\n","      <th>transmission_size_price_max_enc</th>\n","      <th>transmission_type_price_mean_enc</th>\n","      <th>transmission_type_price_max_enc</th>\n","      <th>drive_size_price_mean_enc</th>\n","      <th>drive_size_price_max_enc</th>\n","      <th>drive_type_price_mean_enc</th>\n","      <th>drive_type_price_max_enc</th>\n","      <th>size_type_price_mean_enc</th>\n","      <th>size_type_price_max_enc</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21617</th>\n","      <td>367</td>\n","      <td>2006</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>156081</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>8.769920</td>\n","      <td>10.942385</td>\n","      <td>8.793447</td>\n","      <td>11.146027</td>\n","      <td>8.831379</td>\n","      <td>10.969353</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>8.838854</td>\n","      <td>10.942385</td>\n","    </tr>\n","    <tr>\n","      <th>21326</th>\n","      <td>165</td>\n","      <td>2008</td>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>143323</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>8.769920</td>\n","      <td>10.942385</td>\n","      <td>8.793447</td>\n","      <td>11.146027</td>\n","      <td>8.831379</td>\n","      <td>10.969353</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>8.838854</td>\n","      <td>10.942385</td>\n","    </tr>\n","    <tr>\n","      <th>5317</th>\n","      <td>120</td>\n","      <td>2016</td>\n","      <td>68</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>130992</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.678240</td>\n","      <td>11.465100</td>\n","      <td>9.605630</td>\n","      <td>11.480599</td>\n","      <td>9.769985</td>\n","      <td>11.465100</td>\n","      <td>9.638499</td>\n","      <td>11.465100</td>\n","    </tr>\n","    <tr>\n","      <th>19378</th>\n","      <td>46</td>\n","      <td>2005</td>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>131332</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>8.769920</td>\n","      <td>10.942385</td>\n","      <td>8.879510</td>\n","      <td>11.107660</td>\n","      <td>8.831379</td>\n","      <td>10.969353</td>\n","      <td>8.899706</td>\n","      <td>10.793660</td>\n","      <td>8.872018</td>\n","      <td>10.747745</td>\n","    </tr>\n","    <tr>\n","      <th>2540</th>\n","      <td>184</td>\n","      <td>2000</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>126589</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.002582</td>\n","      <td>11.169801</td>\n","      <td>8.793447</td>\n","      <td>11.146027</td>\n","      <td>9.436102</td>\n","      <td>11.302353</td>\n","      <td>9.264435</td>\n","      <td>11.201074</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4373</th>\n","      <td>220</td>\n","      <td>2014</td>\n","      <td>74</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>123231</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>19809</th>\n","      <td>178</td>\n","      <td>1997</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>45072</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.183054</td>\n","      <td>11.308616</td>\n","      <td>9.484746</td>\n","      <td>11.290856</td>\n","      <td>9.373652</td>\n","      <td>11.318369</td>\n","      <td>9.542093</td>\n","      <td>11.290582</td>\n","      <td>9.638499</td>\n","      <td>11.465100</td>\n","    </tr>\n","    <tr>\n","      <th>5728</th>\n","      <td>366</td>\n","      <td>2007</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>252286</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>8.955201</td>\n","      <td>11.201074</td>\n","    </tr>\n","    <tr>\n","      <th>8100</th>\n","      <td>252</td>\n","      <td>2007</td>\n","      <td>40</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>91799</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.002582</td>\n","      <td>11.169801</td>\n","      <td>8.879510</td>\n","      <td>11.107660</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>8.899706</td>\n","      <td>10.793660</td>\n","      <td>9.147297</td>\n","      <td>11.196967</td>\n","    </tr>\n","    <tr>\n","      <th>3576</th>\n","      <td>323</td>\n","      <td>2014</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>108652</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.436102</td>\n","      <td>11.302353</td>\n","      <td>9.264435</td>\n","      <td>11.201074</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8260 rows × 354 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52e3c213-9713-4f22-8193-5d01d8a3e2e9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-52e3c213-9713-4f22-8193-5d01d8a3e2e9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-52e3c213-9713-4f22-8193-5d01d8a3e2e9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0b820307-d0f4-43ed-b9b2-0f874d97cc42\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b820307-d0f4-43ed-b9b2-0f874d97cc42')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0b820307-d0f4-43ed-b9b2-0f874d97cc42 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["X_test_scaled"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"wKVkEcgYDWFA","executionInfo":{"status":"ok","timestamp":1692540374059,"user_tz":-540,"elapsed":23,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"66b844df-0c0d-479c-ceb6-12a4780b9e1d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       region  year  manufacturer  condition  cylinders  fuel  odometer  \\\n","id                                                                        \n","27532     357  2015            42          0          3     2     92553   \n","27533     271  2013            63          3          3     2    134385   \n","27534       2  2011            74          2          3     2    102489   \n","27535      74  2016            52          0          5     0     64310   \n","27536     134  1999            48          0          6     2    180839   \n","...       ...   ...           ...        ...        ...   ...       ...   \n","55064     121  2016            47          0          5     2     90902   \n","55065     174  2012            63          0          3     2     27234   \n","55066     251  2002            39          0          5     2     99761   \n","55067      60  2006            39          0          5     2    162279   \n","55068     325  2006            52          0          5     2    186965   \n","\n","       title_status  transmission  drive  ...  \\\n","id                                        ...   \n","27532             0             0      1  ...   \n","27533             6             0      1  ...   \n","27534             0             0      1  ...   \n","27535             0             0      0  ...   \n","27536             5             0      0  ...   \n","...             ...           ...    ...  ...   \n","55064             5             0      1  ...   \n","55065             5             0      1  ...   \n","55066             0             0      2  ...   \n","55067             0             0      0  ...   \n","55068             0             0      0  ...   \n","\n","       transmission_size_price_mean_enc  transmission_size_price_max_enc  \\\n","id                                                                         \n","27532                          9.359863                        11.480599   \n","27533                          9.196960                        11.302353   \n","27534                          9.359863                        11.480599   \n","27535                          9.196960                        11.302353   \n","27536                          9.196960                        11.302353   \n","...                                 ...                              ...   \n","55064                          9.359863                        11.480599   \n","55065                          9.196960                        11.302353   \n","55066                          9.359863                        11.480599   \n","55067                          9.196960                        11.302353   \n","55068                          9.359863                        11.480599   \n","\n","       transmission_type_price_mean_enc  transmission_type_price_max_enc  \\\n","id                                                                         \n","27532                          9.309844                        11.480599   \n","27533                          9.007278                        11.201074   \n","27534                          9.007278                        11.201074   \n","27535                          9.309844                        11.480599   \n","27536                          9.309844                        11.480599   \n","...                                 ...                              ...   \n","55064                          9.678240                        11.465100   \n","55065                          9.007278                        11.201074   \n","55066                          9.207098                        11.196967   \n","55067                          9.007278                        11.201074   \n","55068                          9.309844                        11.480599   \n","\n","       drive_size_price_mean_enc  drive_size_price_max_enc  \\\n","id                                                           \n","27532                   8.939408                 11.176921   \n","27533                   9.015053                 11.169801   \n","27534                   8.939408                 11.176921   \n","27535                   9.464871                 11.280665   \n","27536                   9.464871                 11.280665   \n","...                          ...                       ...   \n","55064                   8.939408                 11.176921   \n","55065                   9.015053                 11.169801   \n","55066                   9.373652                 11.318369   \n","55067                   9.464871                 11.280665   \n","55068                   9.605630                 11.480599   \n","\n","       drive_type_price_mean_enc  drive_type_price_max_enc  \\\n","id                                                           \n","27532                   9.048696                 10.969353   \n","27533                   8.917410                 10.942385   \n","27534                   8.917410                 10.942385   \n","27535                   9.442506                 11.480599   \n","27536                   9.442506                 11.480599   \n","...                          ...                       ...   \n","55064                   9.060004                 10.849240   \n","55065                   8.917410                 10.942385   \n","55066                   9.273507                 11.196967   \n","55067                   9.269472                 11.131680   \n","55068                   9.442506                 11.480599   \n","\n","       size_type_price_mean_enc  size_type_price_max_enc  \n","id                                                        \n","27532                  9.290272                11.480599  \n","27533                  9.042572                11.131680  \n","27534                  8.955201                11.201074  \n","27535                  9.262217                11.302353  \n","27536                  9.262217                11.302353  \n","...                         ...                      ...  \n","55064                  9.638499                11.465100  \n","55065                  9.042572                11.131680  \n","55066                  9.101938                11.156222  \n","55067                  9.042572                11.131680  \n","55068                  9.290272                11.480599  \n","\n","[27537 rows x 177 columns]"],"text/html":["\n","  <div id=\"df-0bf9fcdf-941d-444c-be79-0f98a9a05c5e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>year</th>\n","      <th>manufacturer</th>\n","      <th>condition</th>\n","      <th>cylinders</th>\n","      <th>fuel</th>\n","      <th>odometer</th>\n","      <th>title_status</th>\n","      <th>transmission</th>\n","      <th>drive</th>\n","      <th>...</th>\n","      <th>transmission_size_price_mean_enc</th>\n","      <th>transmission_size_price_max_enc</th>\n","      <th>transmission_type_price_mean_enc</th>\n","      <th>transmission_type_price_max_enc</th>\n","      <th>drive_size_price_mean_enc</th>\n","      <th>drive_size_price_max_enc</th>\n","      <th>drive_type_price_mean_enc</th>\n","      <th>drive_type_price_max_enc</th>\n","      <th>size_type_price_mean_enc</th>\n","      <th>size_type_price_max_enc</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27532</th>\n","      <td>357</td>\n","      <td>2015</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>92553</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>9.048696</td>\n","      <td>10.969353</td>\n","      <td>9.290272</td>\n","      <td>11.480599</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>271</td>\n","      <td>2013</td>\n","      <td>63</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>134385</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>27534</th>\n","      <td>2</td>\n","      <td>2011</td>\n","      <td>74</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>102489</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>8.955201</td>\n","      <td>11.201074</td>\n","    </tr>\n","    <tr>\n","      <th>27535</th>\n","      <td>74</td>\n","      <td>2016</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>64310</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.442506</td>\n","      <td>11.480599</td>\n","      <td>9.262217</td>\n","      <td>11.302353</td>\n","    </tr>\n","    <tr>\n","      <th>27536</th>\n","      <td>134</td>\n","      <td>1999</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>180839</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.442506</td>\n","      <td>11.480599</td>\n","      <td>9.262217</td>\n","      <td>11.302353</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>55064</th>\n","      <td>121</td>\n","      <td>2016</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>90902</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.678240</td>\n","      <td>11.465100</td>\n","      <td>8.939408</td>\n","      <td>11.176921</td>\n","      <td>9.060004</td>\n","      <td>10.849240</td>\n","      <td>9.638499</td>\n","      <td>11.465100</td>\n","    </tr>\n","    <tr>\n","      <th>55065</th>\n","      <td>174</td>\n","      <td>2012</td>\n","      <td>63</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>27234</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.015053</td>\n","      <td>11.169801</td>\n","      <td>8.917410</td>\n","      <td>10.942385</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>55066</th>\n","      <td>251</td>\n","      <td>2002</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>99761</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.207098</td>\n","      <td>11.196967</td>\n","      <td>9.373652</td>\n","      <td>11.318369</td>\n","      <td>9.273507</td>\n","      <td>11.196967</td>\n","      <td>9.101938</td>\n","      <td>11.156222</td>\n","    </tr>\n","    <tr>\n","      <th>55067</th>\n","      <td>60</td>\n","      <td>2006</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>162279</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.196960</td>\n","      <td>11.302353</td>\n","      <td>9.007278</td>\n","      <td>11.201074</td>\n","      <td>9.464871</td>\n","      <td>11.280665</td>\n","      <td>9.269472</td>\n","      <td>11.131680</td>\n","      <td>9.042572</td>\n","      <td>11.131680</td>\n","    </tr>\n","    <tr>\n","      <th>55068</th>\n","      <td>325</td>\n","      <td>2006</td>\n","      <td>52</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>186965</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9.359863</td>\n","      <td>11.480599</td>\n","      <td>9.309844</td>\n","      <td>11.480599</td>\n","      <td>9.605630</td>\n","      <td>11.480599</td>\n","      <td>9.442506</td>\n","      <td>11.480599</td>\n","      <td>9.290272</td>\n","      <td>11.480599</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27537 rows × 177 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bf9fcdf-941d-444c-be79-0f98a9a05c5e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0bf9fcdf-941d-444c-be79-0f98a9a05c5e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0bf9fcdf-941d-444c-be79-0f98a9a05c5e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b80f4123-3986-46a2-b605-81665fb7f1b1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b80f4123-3986-46a2-b605-81665fb7f1b1')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b80f4123-3986-46a2-b605-81665fb7f1b1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import lightgbm as lgb\n","from sklearn.model_selection import KFold\n","\n","# LightGBMモデルの初期化\n","all_predictions = []\n","params = {'objective': 'regression',  # 最小化させるべき損失関数\n","          \"max_depth\":128,\n","         \"learing_rate\":0.05,\n","         'random_state': 42,  # 乱数シード\n","         'boosting_type': 'dart',  # boosting_typegbdt\n","         #'n_estimators': 200,\n","          'early_stopping_rounds':50,\n","         'n_estimators':10000# 最大学習サイクル数。early_stopping使用時は大きな値を入力\n","         }\n","\n","model = lgb.LGBMRegressor(**params)\n","def mape(y_true, y_pred):\n","    \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","def evaluate_with_cv_and_evalset(model, X, y,X_test2,y_test2,X_new_test,all_predictions, n_splits=20):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    mape_scores = []\n","\n","\n","    for train_index, test_index in kf.split(X):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","        # 訓練データの一部を評価データセットとして分割\n","        X_train_part, X_eval, y_train_part, y_eval = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","        # eval_setとして評価データセットを指定\n","        eval_set = [(X_eval, y_eval)]\n","\n","        model.fit(X_train_part, y_train_part,  eval_metric='rmse',\n","                  eval_set=eval_set)\n","\n","        # 予測とMAPEスコアの計算\n","        y_pred = model.predict(X_test2)\n","        # 予測を実行\n","        fold_predictions = model.predict(X_new_test)\n","        all_predictions.append(np.expm1(fold_predictions))\n","\n","        current_mape = mape(np.expm1(y_test2), np.expm1(y_pred))\n","        mape_scores.append(current_mape)\n","\n","    return np.mean(mape_scores),all_predictions\n","def remove_duplicate_columns(df):\n","    return df.loc[:,~df.columns.duplicated()]\n","\n","X_train_scaled = remove_duplicate_columns(X_train_scaled)\n","X_val_scaled = remove_duplicate_columns(X_val_scaled)  # There seems to be a typo here as well. Should it be X_val_scaled?\n","X_test_scaled = remove_duplicate_columns(X_test_scaled)\n","\n","# クロスバリデーションとeval_setを使用してモデルを評価\n","average_mape,all_predictions = evaluate_with_cv_and_evalset(model,X_train_scaled,y_train, X_val_scaled,y_val_scaled,X_test_scaled,all_predictions)\n","print(f\"Average MAPE with Cross-Validation and eval_set: {average_mape:.2f}%\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"850kJsQAMSA_","executionInfo":{"status":"ok","timestamp":1692552431576,"user_tz":-540,"elapsed":11700315,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"7954c936-696a-45e0-c1db-715a5ea8b95d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038214 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15784\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.202630\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037091 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15699\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.208353\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040212 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15747\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.204563\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057409 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15751\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.210338\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009967 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 15771\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.211218\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039475 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15811\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.198753\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009457 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 15786\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.212684\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054966 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15765\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.206388\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062854 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15753\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.211009\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035973 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15811\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.205962\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009556 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 15802\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.211005\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009332 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 15725\n","[LightGBM] [Info] Number of data points in the train set: 14646, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.208240\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036317 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15800\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.207180\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009674 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 15816\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.205371\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036750 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15738\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.206888\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009584 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 15722\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.204773\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056784 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15814\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.204114\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009524 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 15688\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.207136\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044738 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15843\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.213493\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038155 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 15783\n","[LightGBM] [Info] Number of data points in the train set: 14647, number of used features: 177\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 9.206420\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:288: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: learing_rate\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","Average MAPE with Cross-Validation and eval_set: 52.59%\n"]}]},{"cell_type":"code","source":["# 1. 平均予測値を計算\n","ensemble_predictions = np.mean(all_predictions, axis=0)\n","\n","# 2. 平均予測値とテストデータのIDを結合して新しいデータフレームを作成\n","results_df = pd.DataFrame({\n","    'ID': X_test_scaled.index,\n","    'Predicted_Price': ensemble_predictions\n","})\n","\n","# 3. 結果のデータフレームを表示\n","print(results_df.head())\n","results_df.to_csv(\"resukt.csv\",encoding=\"cp932\",index=False,header=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPbnzlG0bkkO","executionInfo":{"status":"ok","timestamp":1692552431810,"user_tz":-540,"elapsed":12,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"bfa053aa-98ec-4a15-fe38-ded3d373ae1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      ID  Predicted_Price\n","0  27532     12795.143108\n","1  27533      9206.576411\n","2  27534      6235.230280\n","3  27535     17362.122679\n","4  27536      4562.916921\n"]}]},{"cell_type":"code","source":[" results_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"T2Ba-7O4cszs","executionInfo":{"status":"ok","timestamp":1692462004330,"user_tz":-540,"elapsed":270,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"e13f8ef5-0ea7-4c49-f5e1-a0602affe5bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          ID  Predicted_Price\n","0      27532     11185.862149\n","1      27533      4447.019365\n","2      27534      6012.076998\n","3      27535     17837.774542\n","4      27536     15062.671702\n","...      ...              ...\n","27532  55064      3630.960145\n","27533  55065      8455.373528\n","27534  55066      9195.930210\n","27535  55067     10122.250228\n","27536  55068      5378.954126\n","\n","[27537 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-3f0de97c-0bec-4109-ad57-3f9ea52266e8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Predicted_Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>27532</td>\n","      <td>11185.862149</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27533</td>\n","      <td>4447.019365</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>27534</td>\n","      <td>6012.076998</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27535</td>\n","      <td>17837.774542</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>27536</td>\n","      <td>15062.671702</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27532</th>\n","      <td>55064</td>\n","      <td>3630.960145</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>55065</td>\n","      <td>8455.373528</td>\n","    </tr>\n","    <tr>\n","      <th>27534</th>\n","      <td>55066</td>\n","      <td>9195.930210</td>\n","    </tr>\n","    <tr>\n","      <th>27535</th>\n","      <td>55067</td>\n","      <td>10122.250228</td>\n","    </tr>\n","    <tr>\n","      <th>27536</th>\n","      <td>55068</td>\n","      <td>5378.954126</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27537 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f0de97c-0bec-4109-ad57-3f9ea52266e8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3f0de97c-0bec-4109-ad57-3f9ea52266e8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3f0de97c-0bec-4109-ad57-3f9ea52266e8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3d831e55-a372-44d5-be5a-539d692ca81e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d831e55-a372-44d5-be5a-539d692ca81e')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3d831e55-a372-44d5-be5a-539d692ca81e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["# 新しいセクション"],"metadata":{"id":"6j5sE3qMc4PT"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","from sklearn.linear_model import LinearRegression, Ridge\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.svm import SVR\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","import pandas as pd\n","\n","# Initialize models\n","models = [\n","    (\"Linear Regression\", LinearRegression()),\n","    (\"Ridge Regression\", Ridge()),\n","    (\"Random Forest\", RandomForestRegressor(random_state=42)),\n","    (\"Gradient Boosting\", GradientBoostingRegressor(random_state=42)),\n","    (\"Support Vector Machine\", SVR()),\n","    (\"Neural Network\", MLPRegressor(random_state=42)),\n","    (\"XGBoost\", xgb.XGBRegressor(random_state=42))\n","]\n","\n","def mape(y_true, y_pred):\n","    \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","\n","def evaluate_each_model_no_cv(models, X_train_scaled, X_test_scaled, y_train, y_test):\n","    model_mape_scores = {}\n","    #y_train_log = np.log1p(y_train)  # Log transformation of the training target\n","    for name, model in models:\n","        # Train the model with log-transformed target\n","        model.fit(X_train_scaled, y_train)\n","\n","        # Predict and transform predictions back to original scale\n","        y_pred_log = model.predict(X_test_scaled)\n","        y_pred = np.expm1(y_pred_log)  # Convert from log scale to original scale\n","        y_test_exm = np.expm1(y_test)\n","\n","        # Calculate MAPE with original scale\n","        current_mape = mape(y_test_exm, y_pred)\n","        model_mape_scores[name] = current_mape\n","    return model_mape_scores\n","\n","\n","\n","def ensemble_and_evaluate_no_cv(models, weights, X_train_scaled, X_test_scaled, y_train, y_test):\n","    assert len(models) == len(weights), \"Number of models must match number of weights.\"\n","\n","    weighted_predictions = []\n","    for idx, (name, model) in enumerate(models):\n","        # Make predictions on the test set (assuming models are already trained)\n","        y_pred_log = model.predict(X_test_scaled)\n","        y_pred = np.expm1(y_pred_log)  # Convert from log scale to original scale\n","        weighted_predictions.append(y_pred * weights[idx])\n","\n","    # Ensemble predictions (taking weighted sum of all model predictions)\n","    ensemble_pred = np.sum(weighted_predictions, axis=0)\n","    y_test_exm = np.expm1(y_test)\n","    ensemble_mape = mape(y_test_exm, ensemble_pred)\n","\n","    return ensemble_mape\n","\n","\n","\n","# Evaluate each model without cross-validation\n","average_mape_scores = evaluate_each_model_no_cv(models, X_train_scaled, X_test_scaled, y_train, y_test)\n","for model_name, mape_score in average_mape_scores.items():\n","    print(f\"MAPE for {model_name}: {mape_score}\")\n","\n","# Ensemble evaluation without cross-validation using equal weights\n","weights_equal = [1/len(models) for _ in models]\n","mape_ensemble_equal = ensemble_and_evaluate_no_cv(models, weights_equal, X_train_scaled, X_test_scaled, y_train, y_test)\n","print(\"\\nMAPE for Ensemble with equal weights:\", mape_ensemble_equal)\n","\n","# Ensemble evaluation without cross-validation using custom weights\n","weights_custom = [0.1, 0.1, 0.2, 0.3, 0.1, 0.2, 0.1]  # Added an additional weight for XGBoost\n","mape_ensemble_custom = ensemble_and_evaluate_no_cv(models, weights_custom, X_train_scaled, X_test_scaled, y_train, y_test)\n","print(\"\\nMAPE for Ensemble with custom weights:\", mape_ensemble_custom)\n","\n","\n","# ... The rest of the code for ensemble remains similar but ensure to handle log transformation\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"8nDCHiD_Ej--","executionInfo":{"status":"error","timestamp":1692454834373,"user_tz":-540,"elapsed":25222,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"b00e5a4c-48dc-48f1-f9b9-91459556f08c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-aff74350b032>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Evaluate each model without cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0maverage_mape_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_each_model_no_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmape_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maverage_mape_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"MAPE for {model_name}: {mape_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-aff74350b032>\u001b[0m in \u001b[0;36mevaluate_each_model_no_cv\u001b[0;34m(models, X_train_scaled, X_test_scaled, y_train, y_test)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Train the model with log-transformed target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Predict and transform predictions back to original scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["\n","# 2. Predict using trained models\n","ensemble_predictions_log = np.zeros(len(X_new_test_scaled))  # Initialize with zeros\n","for idx, (name, model) in enumerate(models):\n","    y_pred_log = model.predict(X_new_test_scaled)  # Get predictions in log scale\n","    ensemble_predictions_log += weights_equal[idx] * y_pred_log  # Add weighted predictions\n","\n","ensemble_predictions = np.expm1(ensemble_predictions_log)  # Convert from log scale to original scale\n","\n","# 3. Combine predicted values with the original test data IDs\n","results_df = pd.DataFrame({\n","    'ID': X_new_test.index,\n","    'Predicted_Price': ensemble_predictions\n","})\n","\n","# 4. Display the resulting dataframe\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":463},"id":"JjrsZ9L38KIj","executionInfo":{"status":"error","timestamp":1692024066352,"user_tz":-540,"elapsed":322,"user":{"displayName":"ryota nomura","userId":"09663134500151511258"}},"outputId":"de6e1201-a4de-425f-cf08-ef31c61919e0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-14982d55e27e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mensemble_predictions_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Initialize with zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get predictions in log scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mensemble_predictions_log\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweights_equal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred_log\u001b[0m  \u001b[0;31m# Add weighted predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}]},{"cell_type":"code","source":["\n","import pandas as pd\n","results_df.to_csv(\"resukt.csv\",encoding=\"cp932\",index=False,header=False)\n"],"metadata":{"id":"w6k_WVW6iJge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MccEkE1gikCJ"},"execution_count":null,"outputs":[]}]}